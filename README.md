____________________________________________________________________________________


# Project Template
This is the template for the ETL assignment in the IFRATI 2024-1 court at the Data Science Master, Universidad Icesi, Cali Colombia

This template is based on the template proposed by the [Data Science Working Group] (https://github.com/sfbrigade/data-science-wg) Code for the [San Francisco’s Code initiative](https://github.com/sfbrigade/data-science-wg) 

*Instructions: Edit this template filling in the titles, information, and links! Feel free to stray a bit to suit your project but try to provide the main information for reviews and feedback purposes.*

____________________________________________________________________________________

# Final Project
This project is a part of the  **Proyecto final de Infraestructura y Arquitectura de TI** course in the Data Science Master, Universidad Icesi, Cali Colombia. 

#### -- Project Status: [Active]

## Contributing Members

|Name     |  Email   | 
|---------|-----------------|
|[Claudia Aragon](https://github.com/Clauaragon)| @Clauaragon       |
|[Álvaro J. Cabrera](https://github.com/alvarojcabrera)| @alvarojcabrera   |
|[Alfredo Aponte](https://github.com/ajapontes) |     @ajapontes    |
|[Alvaro Rodriguez](https://github.com/finanzasvlr) |     @finanzasvlr    |


## Contact
* Feel free to contact any of the contributing members with any questions or if you are interested in contributing!


## Project Intro/Objective
The purpose of this project is practice an ETL process using Pentaho.

### Partner
This section should be added when there's a partner institution 
* [Name of Partner organization/Government department etc..]
* Website for partner
* Partner contact: [Name of Contact], [slack handle of contact if any]
* If you do not have a partner leave this section out


### Technologies
* Pentaho 
* MongoDB
* Relational DB

## Project Description
Build the ETL process using Pentaho Data Integration (PDI) in order to obtain a csv file, carrying out the extraction and transformation process of the data available in the BD Ames relational database, in csv files and in MongoDB.

## Getting Started
Instructions for contributors
1. Clone this repo (for help see this [tutorial](https://help.github.com/articles/cloning-a-repository/)).
2. Raw Data is being kept [here](Repo folder containing raw data) within this repo.

    *If using offline data mention that and how contributors may obtain the data )*
    
3. Data processing/transformation scripts are being kept [here](Repo folder containing data processing scripts/notebooks)
4. etc...

*If your project is well underway and setup is fairly complicated (ie. requires installation of many packages) create another "setup.md" file and link to it here*  

5. Follow setup [instructions](Link to file)

## Featured Notebooks/Analysis/Deliverables
* [Notebook/Markdown/Slide Deck Title](link)
* [Notebook/Markdown/Slide DeckTitle](link)
* [Blog Post](link)


